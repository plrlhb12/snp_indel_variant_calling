{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jax IlluminaWGS ## 14Aug, 2020 join calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "1. -mq  -q means quiet, no verbose at all\n",
    "2. gsutil doesn't work on python3.8, which is installed in my plot env\n",
    "3. global varibles and libraries\n",
    "4. Remeber to update the WRKDIR for previously used notebooks\n",
    "5. Remember do not add comments before %%bash\n",
    "6. Remember to replace 'usuhsID' with 'Sample_Name' in sample_ids\n",
    "7. make sure the json or tool dir are there for the next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global notebook variables for both python and bash majic (by stdin arguments)\n",
    "#WRKDIR = '/Users/mooreank/Desktop/Mark/UNHS'\n",
    "WRKDIR = '/Users/pengl7/Downloads/WGS/Jax'\n",
    "#PRJ_BUCKET = 'gs://nihnialngcbg-testing'\n",
    "PRJ_BUCKET = 'gs://test-7cee72c0e768'\n",
    "#PROJECT_ID = 'nih-nia-lng-cbg'\n",
    "PROJECT_ID = 'singlecellseq'\n",
    "#MYUSER = 'mooreank'\n",
    "MYUSER = 'pengl7'\n",
    "AUTOSOMES=[str(x) for x in list(range(1,23))]\n",
    "SEXOMES=['X','Y']\n",
    "CHROMOSOMES=AUTOSOMES + SEXOMES\n",
    "\n",
    "# COHORT='UNHS'\n",
    "# remember the folder sequence should also be the same in the local dir\n",
    "COHORT = 'Jax'\n",
    "\n",
    "# Notice that COHORT_BUCKET means the main data_folder path in the project bucket, instead of a bucket name\n",
    "COHORT_BUCKET=f'{PRJ_BUCKET}/{COHORT}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " -s option: This option allows the positional parameters to be set when invoking an interactive shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://test-7cee72c0e768/Jax\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$PRJ_BUCKET\" \"$COHORT\"\n",
    "PRJ_BUCKET=${1}\n",
    "COHORT=${2}\n",
    "echo ${PRJ_BUCKET}/${COHORT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the number of files inside the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       8\n",
      "gs://test-7cee72c0e768/Jax/ubams\n",
      "gs://test-7cee72c0e768/Jax/ubams/KOLF2-ARID2-A2/\n",
      "gs://test-7cee72c0e768/Jax/ubams/KUCG3-C1/\n",
      "gs://test-7cee72c0e768/Jax/ubams/LNGPI1-C1/\n",
      "gs://test-7cee72c0e768/Jax/ubams/NCRM1-C6/\n",
      "gs://test-7cee72c0e768/Jax/ubams/NCRM5-C5/\n",
      "gs://test-7cee72c0e768/Jax/ubams/NN0003932-C3/\n",
      "gs://test-7cee72c0e768/Jax/ubams/NN0004297-C1/\n",
      "gs://test-7cee72c0e768/Jax/ubams/PGP1-C2/\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$COHORT_BUCKET\"\n",
    "\n",
    "COHORT_BUCKET=${1}\n",
    "\n",
    "gsutil ls ${COHORT_BUCKET}/ubams | wc -l\n",
    "echo ${COHORT_BUCKET}/ubams\n",
    "gsutil ls ${COHORT_BUCKET}/ubams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://test-7cee72c0e768/Jax/ubams/NCRM1-C6/NCRM1-C6_GT20-02407_L003_200221.unmapped.bam\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://test-7cee72c0e768/Jax/ubams/NCRM1-C6/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkfortemplatefile(this_template_file):\n",
    "    if not os.path.isfile(this_template_file):\n",
    "        print('need ' + this_template_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part3:  Alignment: ubam to cram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_Name</th>\n",
       "      <th>usuhsID</th>\n",
       "      <th>Adaptor</th>\n",
       "      <th>S</th>\n",
       "      <th>LANE</th>\n",
       "      <th>READ</th>\n",
       "      <th>NUM</th>\n",
       "      <th>Flowcell</th>\n",
       "      <th>DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KOLF2-ARID2-A2</td>\n",
       "      <td>GT20-02408</td>\n",
       "      <td>AAGTCCAA-TATGAGTA</td>\n",
       "      <td>S303</td>\n",
       "      <td>L003</td>\n",
       "      <td>R1</td>\n",
       "      <td>1</td>\n",
       "      <td>20-cel-001</td>\n",
       "      <td>200221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KUCG3-C1</td>\n",
       "      <td>GT20-02406</td>\n",
       "      <td>TTATAACC-GATATCGA</td>\n",
       "      <td>S306</td>\n",
       "      <td>L003</td>\n",
       "      <td>R1</td>\n",
       "      <td>1</td>\n",
       "      <td>20-cel-001</td>\n",
       "      <td>200221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LNGPI1-C1</td>\n",
       "      <td>GT20-02411</td>\n",
       "      <td>CAAGCTAG-ACATAGCG</td>\n",
       "      <td>S302</td>\n",
       "      <td>L003</td>\n",
       "      <td>R1</td>\n",
       "      <td>1</td>\n",
       "      <td>20-cel-001</td>\n",
       "      <td>200221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCRM1-C6</td>\n",
       "      <td>GT20-02407</td>\n",
       "      <td>GGACTTGG-CGCAGACG</td>\n",
       "      <td>S309</td>\n",
       "      <td>L003</td>\n",
       "      <td>R1</td>\n",
       "      <td>1</td>\n",
       "      <td>20-cel-001</td>\n",
       "      <td>200221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCRM5-C5</td>\n",
       "      <td>GT20-02409</td>\n",
       "      <td>ATCCACTG-AGGTGCGT</td>\n",
       "      <td>S304</td>\n",
       "      <td>L003</td>\n",
       "      <td>R1</td>\n",
       "      <td>1</td>\n",
       "      <td>20-cel-001</td>\n",
       "      <td>200221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_Name     usuhsID            Adaptor     S  LANE READ  NUM  \\\n",
       "0  KOLF2-ARID2-A2  GT20-02408  AAGTCCAA-TATGAGTA  S303  L003   R1    1   \n",
       "1        KUCG3-C1  GT20-02406  TTATAACC-GATATCGA  S306  L003   R1    1   \n",
       "2       LNGPI1-C1  GT20-02411  CAAGCTAG-ACATAGCG  S302  L003   R1    1   \n",
       "3        NCRM1-C6  GT20-02407  GGACTTGG-CGCAGACG  S309  L003   R1    1   \n",
       "4        NCRM5-C5  GT20-02409  ATCCACTG-AGGTGCGT  S304  L003   R1    1   \n",
       "\n",
       "     Flowcell    DATE  \n",
       "0  20-cel-001  200221  \n",
       "1  20-cel-001  200221  \n",
       "2  20-cel-001  200221  \n",
       "3  20-cel-001  200221  \n",
       "4  20-cel-001  200221  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort_df = pd.read_csv(\"../Jax/cohort_df.csv\")\n",
    "cohort_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remember to replace the path of wdl_pipeine.yaml\n",
    "- To follow Raph and Anni's notebook, put all the cram, bam and g.vcf files in the same folder\n",
    "- Next time do not using inputs OUTPUTS=.... as the example in Raph's testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raph's testing\n",
    "# Next time do not using inputs OUTPUTS=.... as the example in Raph's testing\n",
    "gcloud alpha genomics pipelines run \\\n",
    "--project singlecellseq \\\n",
    "--pipeline-file gs://nihnialng-pd-wgs/tools/yamls/wdl_pipeline.yaml \\\n",
    "--zones us-central1-f --memory 7 \\\n",
    "--logging gs://test-7cee72c0e768/Jax/logs/KOLF2-ARID2-A2 \\\n",
    "--inputs-from-file WDL=/labseq/projects/dementia_wgs/tools/broad/PairedEndSingleSampleWf.gatk4.0.wdl \\\n",
    "--inputs-from-file WORKFLOW_INPUTS=/home/gibbsr/KOLF2-ARID2-A2.broadbam.hg38.updated.json \\\n",
    "--inputs-from-file WORKFLOW_OPTIONS=/home/gibbsr/generic.google-papi.options.json \\\n",
    "--inputs WORKSPACE=gs://test-7cee72c0e768/Jax/workspace/KOLF2-ARID2-A2 \\\n",
    "--inputs OUTPUTS=gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22 \\\n",
    "--labels=pipe=ubam_to_cram,sample=kolf2-arid2-a2,cohort=jax,user=gibbsr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.aligned.duplicates_marked.recalibrated.bam.read_group_md5\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.alignment_summary_metrics\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.bai\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.bait_bias_detail_metrics\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.bait_bias_summary_metrics\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.bam\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.cram\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.cram.crai\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.cram.md5\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.cram.validation_report\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.duplicate_metrics\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.g.vcf.gz\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.g.vcf.gz.tbi\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.gc_bias.detail_metrics\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.gc_bias.pdf\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.gc_bias.summary_metrics\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.insert_size_histogram.pdf\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.insert_size_metrics\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.preBqsr.selfSM\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.pre_adapter_detail_metrics\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.pre_adapter_summary_metrics\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.quality_distribution.pdf\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.quality_distribution_metrics\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.raw_wgs_metrics\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.readgroup.alignment_summary_metrics\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.readgroup.gc_bias.detail_metrics\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.readgroup.gc_bias.pdf\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.readgroup.gc_bias.summary_metrics\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.recal_data.csv\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.variant_calling_detail_metrics\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.variant_calling_summary_metrics\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2.wgs_metrics\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2_GT20-02408_L003_200221.unmapped.readgroup.base_distribution_by_cycle.pdf\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2_GT20-02408_L003_200221.unmapped.readgroup.base_distribution_by_cycle_metrics\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2_GT20-02408_L003_200221.unmapped.readgroup.insert_size_histogram.pdf\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2_GT20-02408_L003_200221.unmapped.readgroup.insert_size_metrics\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2_GT20-02408_L003_200221.unmapped.readgroup.quality_by_cycle.pdf\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2_GT20-02408_L003_200221.unmapped.readgroup.quality_by_cycle_metrics\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2_GT20-02408_L003_200221.unmapped.readgroup.quality_distribution.pdf\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2_GT20-02408_L003_200221.unmapped.readgroup.quality_distribution_metrics\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/KOLF2-ARID2-A2_GT20-02408_L003_200221.unmapped.unmapped.quality_yield_metrics\r\n",
      "gs://test-7cee72c0e768/Jax/hg38/align-wf/KOLF2-ARID2-A22/wdl_run_metadata.json\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls {COHORT_BUCKET}/hg38/align-wf/KOLF2-ARID2-A22/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my testing of single run\n",
    "# Next time do not using inputs OUTPUTS=.... as the example in Raph's testing\n",
    "gcloud alpha genomics pipelines run \\\n",
    "--project singlecellseq \\\n",
    "--pipeline-file gs://test-7cee72c0e768/Jax/tools/ggp_wdl_pipeline.yaml \\\n",
    "--zones us-central1-f --memory 7 \\\n",
    "--logging gs://test-7cee72c0e768/Jax/logs/crams/KUCG3-C1 \\\n",
    "--inputs-from-file WDL=/Users/pengl7/Downloads/Jax/tools/broad/PairedEndSingleSampleWf.gatk4.0.wdl \\\n",
    "--inputs-from-file WORKFLOW_INPUTS=/Users/pengl7/Downloads/Jax/jsons/broadbams/KUCG3-C1.broadbam.hg38.updated.json \\\n",
    "--inputs-from-file WORKFLOW_OPTIONS=/Users/pengl7/Downloads/Jax/jsons/PairedEndSingleSampleWf.gatk4.0.options.json \\\n",
    "--inputs WORKSPACE=gs://test-7cee72c0e768/Jax/workspace/KUCG3-C1 \\\n",
    "--inputs OUTPUTS=gs://test-7cee72c0e768/Jax/hg38/align-wf/KUCG3-C1 \\\n",
    "--labels=pipe=ubam_to_cram,sample=kucg3-c1,cohort=jax,user=pengl7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#These actually won't be that helpful because you are all using the same bucket path.\n",
      "\n",
      "#crams\n",
      "       7\n",
      "       7\n",
      "#bams\n",
      "       7\n",
      "       7\n",
      "#gvcfs\n",
      "       7\n"
     ]
    }
   ],
   "source": [
    "#check bam, cram, and gvcf counts which already output into the destination foldere\n",
    "print('#These actually won\\'t be that helpful because you are all using the same bucket path.\\n')\n",
    "print('#crams')\n",
    "!gsutil ls {COHORT_BUCKET}/hg38/align-wf/*/**.cram | wc -l\n",
    "!gsutil ls {COHORT_BUCKET}/hg38/align-wf/*/**.crai | wc -l\n",
    "print('#bams')\n",
    "!gsutil ls {COHORT_BUCKET}/hg38/align-wf/*/**.bam | wc -l\n",
    "!gsutil ls {COHORT_BUCKET}/hg38/align-wf/*/**.bai | wc -l\n",
    "print('#gvcfs')\n",
    "!gsutil ls {COHORT_BUCKET}/hg38/align-wf/*/**.g.vcf.gz | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cautions about NCRM1-C6:\n",
    "- It failed at the last step due to missing of chunks.\n",
    "- The 1st run exited as 1 after exporting all outputs\n",
    "- The 2nd run stopped before finishing. It outputs all cram, bam, gvcf, but missing outputs of CheckPreValidation/ and ValidateCram/\n",
    "- Check the bam file for the suspicious positions using IGV later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://test-7cee72c0e768/Jax/workspace/NCRM1-C6/PairedEndSingleSampleWorkflow/02ee76b6-5159-472e-a3c3-9df43e25905d/\n",
      "gs://test-7cee72c0e768/Jax/workspace/NCRM1-C6/PairedEndSingleSampleWorkflow/4217bcad-b3f6-45bf-84b1-b4896ea4ca57/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls {COHORT_BUCKET}/workspace/NCRM1-C6/PairedEndSingleSampleWorkflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#These actually won't be that helpful because you are all using the same bucket path.\n",
      "\n",
      "#crams\n",
      "       1\n",
      "       1\n",
      "#bams\n",
      "       1\n",
      "       1\n",
      "#gvcfs\n",
      "       1\n"
     ]
    }
   ],
   "source": [
    "#check bam, cram, and gvcf counts of the second run of NCRM1-C6\n",
    "print('#These actually won\\'t be that helpful because you are all using the same bucket path.\\n')\n",
    "print('#crams')\n",
    "!gsutil ls {COHORT_BUCKET}/workspace/NCRM1-C6/PairedEndSingleSampleWorkflow/02ee76b6-5159-472e-a3c3-9df43e25905d/call-ConvertToCram/**.cram | wc -l\n",
    "!gsutil ls {COHORT_BUCKET}/workspace/NCRM1-C6/PairedEndSingleSampleWorkflow/02ee76b6-5159-472e-a3c3-9df43e25905d/call-ConvertToCram/**.crai | wc -l\n",
    "print('#bams')\n",
    "!gsutil ls {COHORT_BUCKET}/workspace/NCRM1-C6/PairedEndSingleSampleWorkflow/02ee76b6-5159-472e-a3c3-9df43e25905d/call-GatherBamFiles/**.bam | wc -l\n",
    "!gsutil ls {COHORT_BUCKET}/workspace/NCRM1-C6/PairedEndSingleSampleWorkflow/02ee76b6-5159-472e-a3c3-9df43e25905d/call-GatherBamFiles/**.bai | wc -l\n",
    "print('#gvcfs')\n",
    "!gsutil ls {COHORT_BUCKET}/workspace/NCRM1-C6/PairedEndSingleSampleWorkflow/02ee76b6-5159-472e-a3c3-9df43e25905d/call-MergeVCFs/**.g.vcf.gz | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#These actually won't be that helpful because you are all using the same bucket path.\n",
      "\n",
      "#crams\n",
      "       1\n",
      "       1\n",
      "#bams\n",
      "       1\n",
      "       1\n",
      "#gvcfs\n",
      "       1\n"
     ]
    }
   ],
   "source": [
    "#check bam, cram, and gvcf counts of the first run of NCRM1-C6\n",
    "print('#These actually won\\'t be that helpful because you are all using the same bucket path.\\n')\n",
    "print('#crams')\n",
    "!gsutil ls {COHORT_BUCKET}/workspace/NCRM1-C6/PairedEndSingleSampleWorkflow/4217bcad-b3f6-45bf-84b1-b4896ea4ca57/call-ConvertToCram/**.cram | wc -l\n",
    "!gsutil ls {COHORT_BUCKET}/workspace/NCRM1-C6/PairedEndSingleSampleWorkflow/4217bcad-b3f6-45bf-84b1-b4896ea4ca57/call-ConvertToCram/**.crai | wc -l\n",
    "print('#bams')\n",
    "!gsutil ls {COHORT_BUCKET}/workspace/NCRM1-C6/PairedEndSingleSampleWorkflow/4217bcad-b3f6-45bf-84b1-b4896ea4ca57/call-GatherBamFiles/**.bam | wc -l\n",
    "!gsutil ls {COHORT_BUCKET}/workspace/NCRM1-C6/PairedEndSingleSampleWorkflow/4217bcad-b3f6-45bf-84b1-b4896ea4ca57/call-GatherBamFiles/**.bai | wc -l\n",
    "print('#gvcfs')\n",
    "!gsutil ls {COHORT_BUCKET}/workspace/NCRM1-C6/PairedEndSingleSampleWorkflow/4217bcad-b3f6-45bf-84b1-b4896ea4ca57/call-MergeVCFs/**.g.vcf.gz | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copying the output files (cram and crai) of the first run of NCRM1-C6 which has validateCram where the second run doesn't have to my final dest path, although they may didn't pass some criteria. The left will be kept for trouble shooting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#run these commands at terminal:\n",
      "\n",
      "#gvcfs\n",
      "gsutil -mq cp gs://test-7cee72c0e768/Jax/workspace/NCRM1-C6/PairedEndSingleSampleWorkflow/4217bcad-b3f6-45bf-84b1-b4896ea4ca57/call-MergeVCFs/**.g.vcf.gz* gs://test-7cee72c0e768/Jax/hg38/align-wf/NCRM1-C6/\n",
      "\n",
      "#crams\n",
      "gsutil -mq cp gs://test-7cee72c0e768/Jax/workspace/NCRM1-C6/PairedEndSingleSampleWorkflow/4217bcad-b3f6-45bf-84b1-b4896ea4ca57/call-ConvertToCram/**.cram* gs://test-7cee72c0e768/Jax/hg38/align-wf/NCRM1-C6/\n",
      "\n",
      "#bams\n",
      "gsutil -mq cp gs://test-7cee72c0e768/Jax/workspace/NCRM1-C6/PairedEndSingleSampleWorkflow/4217bcad-b3f6-45bf-84b1-b4896ea4ca57/call-GatherBamFiles/**.bam gs://test-7cee72c0e768/Jax/hg38/align-wf/NCRM1-C6/\n",
      "\n",
      "#bais\n",
      "gsutil -mq cp gs://test-7cee72c0e768/Jax/workspace/NCRM1-C6/PairedEndSingleSampleWorkflow/4217bcad-b3f6-45bf-84b1-b4896ea4ca57/call-GatherBamFiles/**.bai gs://test-7cee72c0e768/Jax/hg38/align-wf/NCRM1-C6/\n"
     ]
    }
   ],
   "source": [
    "print('#run these commands at terminal:\\n')\n",
    "\n",
    "print('#gvcfs')\n",
    "print('gsutil -mq cp {}/workspace/NCRM1-C6/PairedEndSingleSampleWorkflow/4217bcad-b3f6-45bf-84b1-b4896ea4ca57/call-MergeVCFs/**.g.vcf.gz* \\\n",
    "{}/hg38/align-wf/NCRM1-C6/'.format(COHORT_BUCKET,COHORT_BUCKET))\n",
    "print('\\n#crams')\n",
    "print('gsutil -mq cp {}/workspace/NCRM1-C6/PairedEndSingleSampleWorkflow/4217bcad-b3f6-45bf-84b1-b4896ea4ca57/call-ConvertToCram/**.cram* \\\n",
    "{}/hg38/align-wf/NCRM1-C6/'.format(COHORT_BUCKET,COHORT_BUCKET))\n",
    "print('\\n#bams')\n",
    "print('gsutil -mq cp {}/workspace/NCRM1-C6/PairedEndSingleSampleWorkflow/4217bcad-b3f6-45bf-84b1-b4896ea4ca57/call-GatherBamFiles/**.bam \\\n",
    "{}/hg38/align-wf/NCRM1-C6/'.format(COHORT_BUCKET,COHORT_BUCKET))\n",
    "print('\\n#bais')\n",
    "print('gsutil -mq cp {}/workspace/NCRM1-C6/PairedEndSingleSampleWorkflow/4217bcad-b3f6-45bf-84b1-b4896ea4ca57/call-GatherBamFiles/**.bai \\\n",
    "{}/hg38/align-wf/NCRM1-C6/'.format(COHORT_BUCKET,COHORT_BUCKET))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all the cram, bam and g.vcf files in the same folder\n",
    "Remember: do not use inputs OUTPUTS=.... next time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#run these commands at terminal:\n",
      "\n",
      "#gvcfs\n",
      "gsutil -mq cp gs://test-7cee72c0e768/Jax/hg38/align-wf/*/**.g.vcf.gz* gs://test-7cee72c0e768/Jax/hg38/gvcfs/\n",
      "\n",
      "#crams\n",
      "gsutil -mq cp gs://test-7cee72c0e768/Jax/hg38/align-wf/*/**.cram* gs://test-7cee72c0e768/Jax/hg38/crams/\n",
      "\n",
      "#bams\n",
      "gsutil -mq cp gs://test-7cee72c0e768/Jax/hg38/align-wf/*/**.bam gs://test-7cee72c0e768/Jax/hg38/bams/\n",
      "gsutil -mq cp gs://test-7cee72c0e768/Jax/hg38/align-wf/*/**.bai gs://test-7cee72c0e768/Jax/hg38/bams/\n"
     ]
    }
   ],
   "source": [
    "print('#run these commands at terminal:\\n')\n",
    "\n",
    "print('#gvcfs')\n",
    "print('gsutil -mq cp {}/hg38/align-wf/*/**.g.vcf.gz* \\\n",
    "{}/hg38/gvcfs/'.format(COHORT_BUCKET,COHORT_BUCKET))\n",
    "print('\\n#crams')\n",
    "print('gsutil -mq cp {}/hg38/align-wf/*/**.cram* \\\n",
    "{}/hg38/crams/'.format(COHORT_BUCKET,COHORT_BUCKET))\n",
    "print('\\n#bams')\n",
    "print('gsutil -mq cp {}/hg38/align-wf/*/**.bam \\\n",
    "{}/hg38/bams/'.format(COHORT_BUCKET,COHORT_BUCKET))\n",
    "print('gsutil -mq cp {}/hg38/align-wf/*/**.bai \\\n",
    "{}/hg38/bams/'.format(COHORT_BUCKET,COHORT_BUCKET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#crams\n",
      "       8\n",
      "       8\n",
      "#bams\n",
      "       8\n",
      "       8\n",
      "#gvcfs\n",
      "       8\n",
      "       8\n"
     ]
    }
   ],
   "source": [
    "#confirm counts of the primary output files at final dest path\n",
    "#check bam, cram, and gvcf counts at final path\n",
    "print('#crams')\n",
    "!gsutil ls {COHORT_BUCKET}/hg38/crams/*.cram | wc -l\n",
    "!gsutil ls {COHORT_BUCKET}/hg38/crams/*.crai | wc -l\n",
    "print('#bams')\n",
    "!gsutil ls {COHORT_BUCKET}/hg38/bams/*.bam | wc -l\n",
    "!gsutil ls {COHORT_BUCKET}/hg38/bams/*.bai | wc -l\n",
    "print('#gvcfs')\n",
    "!gsutil ls {COHORT_BUCKET}/hg38/gvcfs/*.g.vcf.gz | wc -l\n",
    "!gsutil ls {COHORT_BUCKET}/hg38/gvcfs/*.g.vcf.gz.tbi | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that all expected files are there by looking at sample IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$WRKDIR\" \"$COHORT_BUCKET\" \"$COHORT\"\n",
    "#get a list of files that were successfully created\n",
    "WRKDIR=${1}\n",
    "COHORT_BUCKET=${2}\n",
    "COHORT=${3}\n",
    "\n",
    "gsutil -mq ls ${COHORT_BUCKET}/hg38/crams/*.cram > ${WRKDIR}/${COHORT}.found.files\n",
    "\n",
    "sed -i -e s\"/gs:\\/\\/test-7cee72c0e768\\/${COHORT}\\/hg38\\/crams\\///\"g ${WRKDIR}/${COHORT}.found.files\n",
    "sed -i -e s\"/\\///\"g ${WRKDIR}/${COHORT}.found.files\n",
    "sed -i -e s\"/\\.cram//\"g ${WRKDIR}/${COHORT}.found.files\n",
    "\n",
    "less ${WRKDIR}/${COHORT}.found.files | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx@ 1 pengl7  1360859114   964B Aug 12 16:29 \u001b[31m/Users/pengl7/Downloads/WGS/Jax/Jax.fastq.listing.txt\u001b[m\u001b[m*\n",
      "-rwxrwxrwx@ 1 pengl7  1360859114   964B Aug 12 16:29 \u001b[31m/Users/pengl7/Downloads/WGS/Jax/Jax.fastq.listing.txt-e\u001b[m\u001b[m*\n",
      "-rwxrwxrwx@ 1 pengl7  1360859114     0B Aug  3 13:41 \u001b[31m/Users/pengl7/Downloads/WGS/Jax/Jax.missing.samples.list\u001b[m\u001b[m*\n",
      "-rwxrwxrwx@ 1 pengl7  1360859114    86B Aug  3 13:41 \u001b[31m/Users/pengl7/Downloads/WGS/Jax/Jax.samples.list\u001b[m\u001b[m*\n"
     ]
    }
   ],
   "source": [
    "%ls -lh /Users/pengl7/Downloads/WGS/Jax/*list*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1)\n",
      "(8, 1)\n",
      "0\n",
      "(0, 1)\n"
     ]
    }
   ],
   "source": [
    "#check for any missing expected bams\n",
    "expected_file = '{}/{}.samples.list'.format(WRKDIR, COHORT)\n",
    "observed_file = '{}/{}.found.files'.format(WRKDIR, COHORT) \n",
    "missing_file = '{}/{}.missing.samples.list'.format(WRKDIR, COHORT)\n",
    "\n",
    "expected = pd.read_csv(expected_file,header=None)\n",
    "observed = pd.read_csv(observed_file,header=None)\n",
    "\n",
    "print(expected.shape)\n",
    "print(observed.shape)\n",
    "\n",
    "print(len(set(expected[0]) - set(observed[0])))\n",
    "\n",
    "missing = expected.loc[~expected[0].isin(observed[0])]\n",
    "print(missing.shape)\n",
    "missing.head()\n",
    "\n",
    "#save the missing list\n",
    "missing.to_csv(missing_file,header=None,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#run these commands at terminal:\n",
      "\n",
      "gsutil -mq cp gs://test-7cee72c0e768/Jax/workspace/*/PairedEndSingleSampleWorkflow/*/call-ValidateCram/**.cram.validation_report gs://test-7cee72c0e768/Jax/hg38/align-wf/call-ValidateCram/\n",
      "\n",
      "gsutil -mq cp gs://test-7cee72c0e768/Jax/workspace/*/PairedEndSingleSampleWorkflow/*/call-CheckContamination/**.preBqsr.selfSM gs://test-7cee72c0e768/Jax/hg38/align-wf/call-CheckContamination/\n",
      "\n",
      "gsutil -mq cp gs://test-7cee72c0e768/Jax/workspace/*/PairedEndSingleSampleWorkflow/*/call-GatherBqsrReports/**.recal_data.csv gs://test-7cee72c0e768/Jax/hg38/align-wf/call-GatherBqsrReports/\n",
      "\n",
      "gsutil -mq cp gs://test-7cee72c0e768/Jax/workspace/*/PairedEndSingleSampleWorkflow/**_metrics gs://test-7cee72c0e768/Jax/hg38/align-wf/metrics/\n",
      "\n",
      "gsutil -mq cp gs://test-7cee72c0e768/Jax/workspace/*/PairedEndSingleSampleWorkflow/**.pdf gs://test-7cee72c0e768/Jax/hg38/align-wf/metrics/\n"
     ]
    }
   ],
   "source": [
    "# move the summary metric files that may be of interest to keep\n",
    "# this block is for the 7 successful samples and one failed \n",
    "print('#run these commands at terminal:\\n')\n",
    "print('gsutil -mq cp {}/workspace/*/PairedEndSingleSampleWorkflow/*/call-ValidateCram/**.cram.validation_report ' \\\n",
    "'{}/hg38/align-wf/call-ValidateCram/'.format(COHORT_BUCKET,COHORT_BUCKET))\n",
    "print('\\ngsutil -mq cp {}/workspace/*/PairedEndSingleSampleWorkflow/*/call-CheckContamination/**.preBqsr.selfSM ' \\\n",
    "'{}/hg38/align-wf/call-CheckContamination/'.format(COHORT_BUCKET,COHORT_BUCKET))\n",
    "print('\\ngsutil -mq cp {}/workspace/*/PairedEndSingleSampleWorkflow/*/call-GatherBqsrReports/**.recal_data.csv ' \\\n",
    "'{}/hg38/align-wf/call-GatherBqsrReports/'.format(COHORT_BUCKET,COHORT_BUCKET))\n",
    "print('\\ngsutil -mq cp {}/workspace/*/PairedEndSingleSampleWorkflow/**_metrics {}/hg38/align-wf/metrics/'.\\\n",
    "      format(COHORT_BUCKET,COHORT_BUCKET))\n",
    "print('\\ngsutil -mq cp {}/workspace/*/PairedEndSingleSampleWorkflow/**.pdf {}/hg38/align-wf/metrics/'.\\\n",
    "      format(COHORT_BUCKET,COHORT_BUCKET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "       8\n",
      "       8\n",
      "       8\n",
      "       8\n",
      "       8\n",
      "       8\n",
      "       8\n",
      "       8\n"
     ]
    }
   ],
   "source": [
    "#check file counts at destination for primary and other metrics output files\n",
    "!gsutil ls {COHORT_BUCKET}/hg38/gvcfs/*.vcf.gz | wc -l\n",
    "!gsutil ls {COHORT_BUCKET}/hg38/gvcfs/*.vcf.gz.tbi | wc -l\n",
    "!gsutil ls {COHORT_BUCKET}/hg38/crams/*.cram | wc -l\n",
    "!gsutil ls {COHORT_BUCKET}/hg38/crams/*.crai | wc -l\n",
    "!gsutil ls {COHORT_BUCKET}/hg38/bams/*.bam | wc -l\n",
    "!gsutil ls {COHORT_BUCKET}/hg38/bams/*.bai | wc -l\n",
    "!gsutil ls {COHORT_BUCKET}/hg38/align-wf/call-ValidateCram/*.cram.validation_report | wc -l\n",
    "!gsutil ls {COHORT_BUCKET}/hg38/align-wf/call-CheckContamination/*.preBqsr.selfSM | wc -l\n",
    "!gsutil ls {COHORT_BUCKET}/hg38/align-wf/call-GatherBqsrReports/*.recal_data.csv | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check the cram validation reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "       8\n"
     ]
    }
   ],
   "source": [
    "# pull down the validation reports and check for erros\n",
    "# for NCRM1-C6 first run, it passed the checkCram\n",
    "!mkdir -p {WRKDIR}/temp\n",
    "\n",
    "!gsutil -mq cp {COHORT_BUCKET}/hg38/align-wf/call-ValidateCram/*.cram.validation_report {WRKDIR}/temp/\n",
    "\n",
    "!ls {WRKDIR}/temp/*.validation_report | wc -l\n",
    "!less {WRKDIR}/temp/*.validation_report | grep \"No errors found\" | wc -l\n",
    "\n",
    "#clean up the temp validation reports\n",
    "!rm {WRKDIR}/temp/*.validation_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This step can be executated later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do some additional cleanup, including deletion of the ubams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if successfully, clean up log files and workspace path\n",
    "print('gsutil -mq rm -r {}/logs/crams'.format(COHORT_BUCKET))\n",
    "print('gsutil -mq rm -r {}/workspace'.format(COHORT_BUCKET))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define format function the gcp cmd to delete additional per sample un-needed files\n",
    "def formatgcpcmd(this_sample,chrt_bucket):\n",
    "    this_cmd = 'gsutil -mq rm -r {COHORT_BUCKET}/hg38/align-wf/{SAMPLE}/PairedEndSingleSampleWorkflow'\n",
    "    return(this_cmd.format(COHORT_BUCKET=chrt_bucket,SAMPLE=this_sample))\n",
    "\n",
    "#here reloading sample_ids\n",
    "cohort_file_list = '{}/{}.samples.list'.format(WRKDIR,COHORT)\n",
    "sample_ids = pd.read_csv(cohort_file_list,header=None).to_numpy()\n",
    "sample_ids = sample_ids.reshape(len(sample_ids))\n",
    "\n",
    "#iterate over samples formatting the cmds\n",
    "cmds = [formatgcpcmd(sample_id,COHORT_BUCKET) for sample_id in sample_ids]\n",
    "\n",
    "temp_script_file = '{}/{}.delete_other_files.sh'.format(WRKDIR,COHORT.lower())\n",
    "\n",
    "with open(temp_script_file, 'w') as file_handler:\n",
    "        for this_cmd in cmds:\n",
    "            file_handler.write(\"{}\\n\".format(this_cmd))\n",
    "            \n",
    "print('#run these commands at terminal:\\n')\n",
    "print('#I\\'VE ALREADY RUN THIS SO DO NOT NEED TO DELETE AGAIN\\n')\n",
    "print('chmod +x ' + temp_script_file)\n",
    "print('nohup ' + temp_script_file + ' > {}/{}.delete_other_files.log &'.format(WRKDIR,COHORT.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##didnt do this yet\n",
    "\n",
    "#define format function the ggp cmd to delete ubams\n",
    "def formatgcpcmd(this_sample,chrt_bucket):\n",
    "    this_cmd = 'gsutil -mq rm -r {COHORT_BUCKET}/ubams/{SAMPLE}'\n",
    "    return(this_cmd.format(COHORT_BUCKET=chrt_bucket,SAMPLE=this_sample))\n",
    "\n",
    "#iterate over samples formatting the cmds\n",
    "cmds = [formatgcpcmd(sample_id,COHORT_BUCKET) for sample_id in sample_ids]\n",
    "\n",
    "temp_script_file = '{}/{}.delete_ubams.sh'.format(WRKDIR,COHORT.lower())\n",
    "\n",
    "with open(temp_script_file, 'w') as file_handler:\n",
    "        for this_cmd in cmds:\n",
    "            file_handler.write(\"{}\\n\".format(this_cmd))\n",
    "            \n",
    "print('#run these commands at terminal:\\n')\n",
    "print('#I\\'VE ALREADY RUN THIS SO DO NOT NEED TO DELETE AGAIN\\n')\n",
    "print('chmod +x ' + temp_script_file)\n",
    "print('nohup ' + temp_script_file + ' > {}/{}.delete_ubams.log &'.format(WRKDIR,COHORT.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The above hasn't been executed yet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check for any contaminated samples\n",
    "pull down seq contamination check info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Updates are available for some Cloud SDK components.  To install them,\n",
      "please run:\n",
      "  $ gcloud components update\n",
      "\n",
      "       8\n"
     ]
    }
   ],
   "source": [
    "#pull down the verifybamid check contamination files \n",
    "!mkdir -p {WRKDIR}/seqqc\n",
    "\n",
    "!gsutil -mq cp {COHORT_BUCKET}/hg38/align-wf/call-CheckContamination/*.preBqsr.selfSM {WRKDIR}/seqqc/\n",
    "!ls {WRKDIR}/seqqc/*.preBqsr.selfSM | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check contamination info and export to the file of .contam.metrics.txt\n",
    "sample_file = f'{WRKDIR}/{COHORT}.samples.list'\n",
    "\n",
    "samples_list= []\n",
    "with open(sample_file, 'r') as fi:\n",
    "    for line in fi:\n",
    "        line = line.strip()\n",
    "        samples_list.append(str(line))\n",
    "        \n",
    "\n",
    "with open(f\"{WRKDIR}/{COHORT}.contam.metrics.txt\", \"w\") as text_file:\n",
    "    text_file.write(\"id avgdp freemix \\n\")\n",
    "    \n",
    "for sample in samples_list:\n",
    "    cmd = f\"\"\"awk 'NR==2{{print $1,$6,$7}}' {WRKDIR}/seqqc/{sample}.preBqsr.selfSM >> {WRKDIR}/{COHORT}.contam.metrics.txt\"\"\"\n",
    "    !{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found 7 out of 8 samples have the avgdp less than the mininal depth\n",
    "- checked the batch of our Psomagen data and found all of them are much higher than the minial depth (27), for example, KOLF2-ARID2 is 41 and NCRM1-C6 is 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3)\n",
      "number of samples maybe contaminated with freemix > 0.02 and < 0.049 is 0\n",
      "number of samples with freemix > 0.049 is 0\n",
      "number of samples with avgdp < 27 is 7\n"
     ]
    }
   ],
   "source": [
    "#check the contamination and seq coverage rates\n",
    "contam_metrics_file = '{}/{}.contam.metrics.txt'.format(WRKDIR,COHORT)\n",
    "\n",
    "WARN_FREEMIX = 0.02\n",
    "MAX_FREEMIX = 0.049\n",
    "MIN_DEPTH = 27\n",
    "\n",
    "metrics_df = pd.read_csv(contam_metrics_file,sep='\\s+')\n",
    "print(metrics_df.shape)\n",
    "metrics_df.head()\n",
    "\n",
    "maybe_contamin_df = metrics_df.loc[(metrics_df['freemix'] <= MAX_FREEMIX) & \\\n",
    "                                   (metrics_df['freemix'] > WARN_FREEMIX)]\n",
    "print('number of samples maybe contaminated with freemix > {} and < {} is {}'\\\n",
    "      .format(WARN_FREEMIX,MAX_FREEMIX,maybe_contamin_df.shape[0]))\n",
    "contam_maybe_file = '{}/{}.contamination.possible.samples.txt'.format(WRKDIR,COHORT)\n",
    "maybe_contamin_df.to_csv(contam_maybe_file,index=False,sep='\\t')\n",
    "\n",
    "contaminated_df = metrics_df.loc[metrics_df['freemix'] > MAX_FREEMIX]\n",
    "print('number of samples with freemix > {} is {}'.format(MAX_FREEMIX,contaminated_df.shape[0]))\n",
    "contam_problems_file = '{}/{}.contaminated.samples.txt'.format(WRKDIR,COHORT)\n",
    "contaminated_df.to_csv(contam_problems_file,index=False,sep='\\t')\n",
    "\n",
    "low_cov_df = metrics_df.loc[metrics_df['avgdp'] < MIN_DEPTH]\n",
    "print('number of samples with avgdp < {} is {}'.format(MIN_DEPTH,low_cov_df.shape[0]))\n",
    "low_coverage_file = '{}/{}.low_coverage.samples.txt'.format(WRKDIR,COHORT)\n",
    "low_cov_df.to_csv(low_coverage_file,index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the number of samples contaminated is 0, we can go ahead to joint genotyping\n",
    "### Generate two jsons files need for joint genotyping\n",
    "1. specify the options for join genotyping using the generic.googlee-papi.options.json template\n",
    "2. specify the gvcf map text, callset name, sample name map using the joint-discovery-gatk4.hg38.wgs.inputs.json template\n",
    "\n",
    "- updated the old joint-discovery-gatk4.hg38.wgs.inputs.json with the new broad bucket name\n",
    "- I changed the bucket name in place, becasue no need to keep the old one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update some of the json configs for broad joint calling\n",
    "#generate the extra json files for ubams to crams; ie labels and options for alignment wf\n",
    "\n",
    "# generic_options_template = f'{WRKDIR}/jsons/generic.google-papi.options.json'\n",
    "# wdl_input_template = f'{WRKDIR}/jsons/JointGenotyping.hg38.wgs.inputs.json'\n",
    "\n",
    "#json_labels_outfile_name = '{}/jsons/{}.JointGenotyping.labels.json'.format(WRKDIR,COHORT)\n",
    "# json_options_outfile_name = f'{WRKDIR}/jsons/{COHORT}.JointGenotyping.options.json'\n",
    "# json_broad_outfile_name = f'{WRKDIR}/jsons/{COHORT}.JointGenotyping.hg38.wgs.inputs.json'  \n",
    "\n",
    "generic_options_template = f'{WRKDIR}/jsons/generic.google-papi.options.json'\n",
    "wdl_input_template = f'{WRKDIR}/jsons/joint-discovery-gatk4.hg38.wgs.inputs.json'\n",
    "\n",
    "#json_labels_outfile_name = '{}/jsons/{}.jdgatk4.labels.json'.format(WRKDIR,COHORT)\n",
    "json_options_outfile_name = f'{WRKDIR}/jsons/{COHORT}.jdgatk4.options.json'\n",
    "json_broad_outfile_name = f'{WRKDIR}/jsons/{COHORT}.jdgatk4.hg38.wgs.inputs.json'\n",
    "\n",
    "#format and write the label json\n",
    "# label_data = {}\n",
    "# label_data['workflow'] = 'jdgatk4'\n",
    "# label_data['cohort'] = COHORT.lower()\n",
    "# label_data['user'] = MYUSER.lower()\n",
    "\n",
    "# with open(json_labels_outfile_name,'w') as json_outfile:\n",
    "#     json.dump(label_data,json_outfile,sort_keys=True,indent=4)   \n",
    "\n",
    "#format and write the options json\n",
    "with open(generic_options_template) as json_file:  \n",
    "    options_data = json.load(json_file)\n",
    "    \n",
    "    options_data['read_from_cache'] = True\n",
    "    options_data['write_to_cache'] = True\n",
    "    options_data['workflow_failure_mode'] = 'ContinueWhilePossible'\n",
    "    options_data['system.input-read-limits.lines'] = 640000    \n",
    "    options_data['final_workflow_outputs_dir'] = '{}/hg38/joint_calling'.format(COHORT_BUCKET)\n",
    "    options_data['final_workflow_log_dir'] = '{}/logs/joint_calling'.format(COHORT_BUCKET)\n",
    "    options_data['final_call_logs_dir'] = '{}/logs/joint_calling'.format(COHORT_BUCKET)\n",
    "\n",
    "    with open(json_options_outfile_name,'w') as json_outfile:\n",
    "        json.dump(options_data,json_outfile,sort_keys=True,indent=4)   \n",
    "\n",
    "#format and write the broad json\n",
    "with open(wdl_input_template) as json_file:  \n",
    "    broad_data = json.load(json_file)\n",
    "    \n",
    "    sample_gvcfs_path = '{}/{}.sample.gvcfs.map.txt'.format(COHORT_BUCKET,COHORT)\n",
    "    broad_data['JointGenotyping.callset_name'] = COHORT\n",
    "    broad_data['JointGenotyping.sample_name_map'] = sample_gvcfs_path\n",
    "\n",
    "    with open(json_broad_outfile_name,'w') as json_outfile:\n",
    "        json.dump(broad_data,json_outfile,sort_keys=False,indent=4)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the gvcfs sample map file used as json argument above JointGenotyping.sample_name_map\n",
    "#instead of just looping expected ids do so from found list in previous cell, allow to move/remove fails\n",
    "\n",
    "found_file_list = '{}/{}.found.files'.format(WRKDIR,COHORT)\n",
    "found_ids = pd.read_csv(found_file_list,header=None).to_numpy()\n",
    "# found_ids = sample_ids.reshape(len(found_ids))\n",
    "found_ids = found_ids.reshape(len(found_ids))\n",
    "\n",
    "gvcfs_map_file = '{}/{}.sample.gvcfs.map.txt'.format(WRKDIR,COHORT)\n",
    "\n",
    "with open(gvcfs_map_file, 'w') as file_handler:\n",
    "    for sample_id in found_ids:\n",
    "        file_handler.write(\"{}\\t{}/hg38/gvcfs/{}.g.vcf.gz\\n\".\\\n",
    "                           format(sample_id,COHORT_BUCKET,sample_id))\n",
    "\n",
    "#now copy the map file up to cloud bucket\n",
    "!gsutil -mq cp {gvcfs_map_file} {COHORT_BUCKET}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output diretory has been pre-defined here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#run these commands at terminal:\n",
      "\n",
      "nohup gcloud alpha genomics pipelines run --project singlecellseq --pipeline-file gs://test-7cee72c0e768/Jax/tools/ggp_wdl_pipeline.yaml --zones us-central1-f --memory 7 --logging gs://test-7cee72c0e768/Jax/logs/joint-discovery/ --inputs-from-file WDL=/Users/pengl7/Downloads/WGS/Jax/tools/broad/joint-discovery-gatk4.wdl --inputs-from-file WORKFLOW_INPUTS=/Users/pengl7/Downloads/WGS/Jax/jsons/Jax.jdgatk4.hg38.wgs.inputs.json --inputs-from-file WORKFLOW_OPTIONS=/Users/pengl7/Downloads/WGS/Jax/jsons/Jax.jdgatk4.options.json --inputs WORKSPACE=gs://test-7cee72c0e768/Jax/workspace/ --inputs OUTPUTS=gs://test-7cee72c0e768/Jax/hg38/joint-discovery/ --labels=pipe=jointdiscovery,cohort=jax,user=pengl7 > /Users/pengl7/Downloads/WGS/Jax/jax.joint-discovery.log &\n"
     ]
    }
   ],
   "source": [
    "#now run the joint calling job\n",
    "\n",
    "# run_cmd = 'python {wrk_dir}/jsons/cromwell_client.py \\\n",
    "# --wdl {wrk_dir}/tools/joint-discovery-gatk4.wdl \\\n",
    "# --workflow-inputs {wrk_dir}/jsons/{this_cohort}.jdgatk4.hg38.wgs.inputs.json \\\n",
    "# --workflow-options {wrk_dir}/jsons/{this_cohort}.jdgatk4.options.json \\\n",
    "# --workflow-labels {wrk_dir}/jsons/{this_cohort}.jdgatk4.labels.json'.\\\n",
    "# format(wrk_dir=WRKDIR, this_cohort=COHORT)\n",
    "\n",
    "# print('#run these commands at terminal:\\n')\n",
    "\n",
    "# print('{} > {}/{}.jdgatk4.jobid'.format(run_cmd, WRKDIR, COHORTBUILD))\n",
    "\n",
    "cohort_bucket = f'{PRJ_BUCKET}/{COHORT}'\n",
    "\n",
    "def formatgcpcmd(chrt_bucket):\n",
    "    this_cmd = 'gcloud alpha genomics pipelines run \\\n",
    "--project {PROJECT_ID} \\\n",
    "--pipeline-file {COHORT_BUCKET}/tools/ggp_wdl_pipeline.yaml \\\n",
    "--zones us-central1-f \\\n",
    "--memory 7 \\\n",
    "--logging {COHORT_BUCKET}/logs/joint-discovery/ \\\n",
    "--inputs-from-file WDL={WRKDIR}/tools/broad/joint-discovery-gatk4.wdl \\\n",
    "--inputs-from-file WORKFLOW_INPUTS={WRKDIR}/jsons/{COHORT}.jdgatk4.hg38.wgs.inputs.json \\\n",
    "--inputs-from-file WORKFLOW_OPTIONS={WRKDIR}/jsons/{COHORT}.jdgatk4.options.json \\\n",
    "--inputs WORKSPACE={COHORT_BUCKET}/workspace/ \\\n",
    "--inputs OUTPUTS={COHORT_BUCKET}/hg38/joint-discovery/ \\\n",
    "--labels=pipe=jointdiscovery,cohort={LCCOHORT},user={MYUSER}'\n",
    "    return(this_cmd.format(PROJECT_ID=PROJECT_ID,PRJ_BUCKET=PRJ_BUCKET,COHORT=COHORT,\\\n",
    "                         COHORT_BUCKET=chrt_bucket,WRKDIR=WRKDIR,LCCOHORT=COHORT.lower(),MYUSER=MYUSER))\n",
    "\n",
    "# #iterate over samples formatting the cmds\n",
    "# cohort_bucket = '{}/{}'.format(PRJ_BUCKET,COHORT)\n",
    "# cmds = [formatgcpcmd(sample_id,cohort_bucket) for sample_id in sample_ids]\n",
    "\n",
    "# temp_script_file = '{}/{}.run_JointGenotyping.sh'.format(WRKDIR,COHORT.lower())\n",
    "\n",
    "final_cmd = formatgcpcmd(cohort_bucket)\n",
    "\n",
    "# with open(temp_script_file, 'w') as file_handler:\n",
    "#         for this_cmd in cmds:\n",
    "#             file_handler.write(\"{}\\n\".format(this_cmd))\n",
    "            \n",
    "print('#run these commands at terminal:\\n')\n",
    "#print('chmod +x ' + final_cmd)\n",
    "print('nohup ' +final_cmd + ' > {}/{}.joint-discovery.log &'.format(WRKDIR,COHORT.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.68 GiB  2020-08-25T15:04:43Z  gs://test-7cee72c0e768/Jax/hg38/joint-discovery/Jax.vcf.gz\n",
      "  2.55 MiB  2020-08-25T15:04:43Z  gs://test-7cee72c0e768/Jax/hg38/joint-discovery/Jax.vcf.gz.tbi\n",
      "TOTAL: 2 objects, 1801354867 bytes (1.68 GiB)\n"
     ]
    }
   ],
   "source": [
    "# see if result file is present, the below command didn't work becaue out output dir has been predefined in the pipeline run\n",
    "#!gsutil ls -lh {COHORT_BUCKET}/hg38/joint_calling/*/{COHORTBUILD}.vcf.gz*\n",
    "\n",
    "!gsutil ls -lh {COHORT_BUCKET}/hg38/joint-discovery/*.vcf.gz*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://test-7cee72c0e768/Jax/hg38/joint_calling/JointGenotyping/8f1d94f8-efb4-4c0c-a4fe-35a6e86c5c38/call-CollectMetricsOnFullVcf/\n",
      "gs://test-7cee72c0e768/Jax/hg38/joint_calling/JointGenotyping/8f1d94f8-efb4-4c0c-a4fe-35a6e86c5c38/call-DynamicallyCombineIntervals/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls {COHORT_BUCKET}/hg38/joint_calling/JointGenotyping/8f1d94f8-efb4-4c0c-a4fe-35a6e86c5c38/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block hasn't been executed yet since we already output file directly to the dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COHORTBUILD = 'UNHS'\n",
    "#job was run twice to two sets of outputs, grab one and then do some cleanup\n",
    "print('#run these commands at terminal:\\n')\n",
    "print('#I\\'VE ALREADY RUN THIS SO DO NOT NEED TO RUN AGAIN\\n')\n",
    "in_path = f'{COHORT_BUCKET}/hg38/joint_calling/JointGenotyping/0822e1a2-f073-49fa-8dd3-bd9519dc7781'\n",
    "out_path = f'{COHORT_BUCKET}/hg38/JointGenotyping/'\n",
    "#print(f'gsutil -mq cp {in_path }/call-DynamicallyCombineIntervals/{COHORTBUILD}.vcf.gz* {out_path}')\n",
    "print(f'gsutil -mq cp {in_path }/call-CollectMetricsOnFullVcf/* {out_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://test-7cee72c0e768/Jax/logs/KOLF2-ARID2-A2/\n",
      "gs://test-7cee72c0e768/Jax/logs/crams/\n",
      "gs://test-7cee72c0e768/Jax/logs/joint-discovery/\n",
      "gs://test-7cee72c0e768/Jax/logs/joint_calling/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls {COHORT_BUCKET}/logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#run these commands at terminal:\n",
      "\n",
      "#I'VE ALREADY RUN THIS SO DO NOT NEED TO RUN AGAIN\n",
      "\n",
      "gsutil -mq rm gs://test-7cee72c0e768/Jax/hg38/joint_calling/JointGenotyping/*/call-FinalGatherVcf/Jax.vcf.gz*\n",
      "gsutil -mq rm gs://test-7cee72c0e768/Jax/hg38/joint_calling/JointGenotyping/*/call-CollectMetricsOnFullVcf/*\n",
      "gsutil -mq rm gs://test-7cee72c0e768/Jax/hg38/joint_calling/JointGenotyping/*/call-DynamicallyCombineIntervals/*\n",
      "gsutil -mq rm -r gs://test-7cee72c0e768/Jax/hg38/joint_calling/JointGenotyping/*\n",
      "gsutil -mq rm -r gs://test-7cee72c0e768/Jax/logs/j*\n"
     ]
    }
   ],
   "source": [
    "# clean up\n",
    "#delete logging, cromwell execution path, and detritus from output path\n",
    "in_path = f'{COHORT_BUCKET}/hg38/joint_calling/JointGenotyping/*'\n",
    "print('#run these commands at terminal:\\n')\n",
    "print('#I\\'VE ALREADY RUN THIS SO DO NOT NEED TO RUN AGAIN\\n')\n",
    "\n",
    "print(f'gsutil -mq rm {in_path}/call-FinalGatherVcf/{COHORT}.vcf.gz*')\n",
    "print(f'gsutil -mq rm {in_path}/call-CollectMetricsOnFullVcf/*')\n",
    "print(f'gsutil -mq rm {in_path}/call-DynamicallyCombineIntervals/*')\n",
    "print(f'gsutil -mq rm -r {COHORT_BUCKET}/hg38/joint_calling/JointGenotyping/*')\n",
    "\n",
    "print(f'gsutil -mq rm -r {COHORT_BUCKET}/logs/j*')\n",
    "#print(f'gsutil -mq rm -r {COHORT_BUCKET}/cromwell-execution/JointGenotyping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part4: subset vcfs to just PASSED variants\n",
    "\n",
    "VQSR doesn't really work for the non-PAR sexomes and while you probably won't be doing analsys on sexome variation you will need at lest chrX to perform sex check QC¶\n",
    "\n",
    "so submit another vcf subset but only for chrX without PASS filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('#run these commands at terminal:\\n')\n",
    "#prep and run the VQSR subset job\n",
    "print(f'cut -f 1 {WRKDIR}/{COHORT}.sample.gvcfs.map.txt > {WRKDIR}/{COHORT}.samples.list\\n')\n",
    "print(f'gsutil -mq cp {WRKDIR}/{COHORT}.samples.list {COHORT_BUCKET}/\\n')\n",
    "\n",
    "pipe_yaml = 'gs://nihnialngcbg-testing/tools/SubjectSubsetVCF.yaml'\n",
    "\n",
    "filter_vqsr_cmd = f'gcloud alpha genomics pipelines run \\\n",
    "--project {PROJECT_ID} \\\n",
    "--pipeline-file {pipe_yaml} \\\n",
    "--logging {COHORT_BUCKET}/logs/jointcall/filtervcf/ \\\n",
    "--inputs INPUTVCF={COHORT_BUCKET}/joint-discovery/{COHORTBUILD}.vcf.gz \\\n",
    "--inputs INPUTVCFINDEX={COHORT_BUCKET}/joint-discovery/{COHORTBUILD}.vcf.gz.tbi \\\n",
    "--inputs SUBJECTLIST={COHORT_BUCKET}/{COHORTBUILD}.samples.list \\\n",
    "--inputs EXCLUDECARROT=\\\" \\\" \\\n",
    "--inputs FILTERFLAGS=\\\"-f PASS --force-samples\\\" \\\n",
    "--inputs MINAC=\\\"1\\\" \\\n",
    "--outputs OUTVCF={COHORT_BUCKET}/hg38/genotypes/{COHORTBUILD}.vcf.gz \\\n",
    "--outputs OUTVCFINDEX={COHORT_BUCKET}/hg38/genotypes/{COHORTBUILD}.vcf.gz.tbi \\\n",
    "--labels=pipe=filtervcfs,cohort={COHORT.lower()},user={MYUSER}\\n'\n",
    "\n",
    "print(filter_vqsr_cmd)\n",
    "\n",
    "chrx_vcf_cmd = f'gcloud alpha genomics pipelines run \\\n",
    "--project {PROJECT_ID} \\\n",
    "--pipeline-file {pipe_yaml} \\\n",
    "--logging {COHORT_BUCKET}/logs/jointcall/filtervcf/ \\\n",
    "--inputs INPUTVCF={COHORT_BUCKET}/joint-discovery/{COHORTBUILD}.vcf.gz \\\n",
    "--inputs INPUTVCFINDEX={COHORT_BUCKET}/joint-discovery/{COHORTBUILD}.vcf.gz.tbi \\\n",
    "--inputs SUBJECTLIST={COHORT_BUCKET}/{COHORTBUILD}.samples.list \\\n",
    "--inputs EXCLUDECARROT=\\\" \\\" \\\n",
    "--inputs FILTERFLAGS=\\\"--regions chrX --force-samples\\\" \\\n",
    "--inputs MINAC=\\\"1\\\" \\\n",
    "--outputs OUTVCF={COHORT_BUCKET}/hg38/genotypes/{COHORTBUILD}.chrX.vcf.gz \\\n",
    "--outputs OUTVCFINDEX={COHORT_BUCKET}/hg38/genotypes/{COHORTBUILD}.chrX.vcf.gz.tbi \\\n",
    "--labels=pipe=filtervcfs,cohort={COHORT.lower()},chromosome=chrx,user={MYUSER}\\n'\n",
    "\n",
    "print(chrx_vcf_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "cmd2 = f'gcloud compute instances list --project {PROJECT_ID} | grep RUNNING | wc -l'\n",
    "!{cmd2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: true\n",
      "metadata:\n",
      "  events:\n",
      "  - description: start\n",
      "    startTime: '2020-08-19T15:13:56.614257047Z'\n",
      "  - description: pulling-image\n",
      "    startTime: '2020-08-19T15:13:56.614330643Z'\n",
      "  - description: localizing-files\n",
      "    startTime: '2020-08-19T15:14:29.732031166Z'\n",
      "  - description: running-docker\n",
      "    startTime: '2020-08-19T15:14:29.732071540Z'\n",
      "  - description: delocalizing-files\n",
      "    startTime: '2020-08-19T23:12:10.280716580Z'\n",
      "  - description: ok\n",
      "    startTime: '2020-08-19T23:12:11.306508509Z'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%bash\n",
    "\n",
    "OPID=EIjRoLrALhjnvYfhzqb_v7YBINHhrPbMCCoPcHJvZHVjdGlvblF1ZXVl\n",
    "gcloud alpha genomics operations describe ${OPID} \\\n",
    "--format='yaml(done, error, metadata.events)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the example lifesciencee pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export GATK_GOOGLE_DIR=\"${PWD}\"/broad-prod-wgs-germline-snps-indels\n",
    "!export GATK_OUTPUT_DIR=gs://transfer_27may/beta_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcloud beta lifesciences pipelines run \\\n",
    "--project singlecellseq \\\n",
    "--pipeline-file gs://transfer_27may/Jax/tools/glsp_wdl_pipeline.yaml \\\n",
    "--location us-central1 \\\n",
    "--regions us-central1 \\\n",
    "--inputs-from-file WDL=${GATK_GOOGLE_DIR}/PairedEndSingleSampleWf.wdl,\\\n",
    "WORKFLOW_INPUTS=${GATK_GOOGLE_DIR}/PairedEndSingleSampleWf.hg38.inputs.json,\\\n",
    "WORKFLOW_OPTIONS=${GATK_GOOGLE_DIR}/PairedEndSingleSampleWf.options.json \\\n",
    "--env-vars WORKSPACE=${GATK_OUTPUT_DIR}/work,\\\n",
    "OUTPUTS=${GATK_OUTPUT_DIR}/output \\\n",
    "--logging ${GATK_OUTPUT_DIR}/logging/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmd2 = f'gcloud compute instances list --project {PROJECT_ID} | grep RUNNING | wc -l'\n",
    "!{cmd2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "OPID=2439314507554778382\n",
    "gcloud beta lifesciences operations describe --project singlecellseq ${OPID} \\\n",
    "--format='yaml(done, error, metadata.events)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
